{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "tf.set_random_seed(777)  # reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data/train-images-idx3-ubyte.gz\n",
      "Extracting ../data/train-labels-idx1-ubyte.gz\n",
      "Extracting ../data/t10k-images-idx3-ubyte.gz\n",
      "Extracting ../data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"../data/\", one_hot=True)\n",
    "# Check out https://www.tensorflow.org/get_started/mnist/beginners for\n",
    "# more information about the mnist dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# hyper parameters\n",
    "learning_rate = 0.001\n",
    "training_epochs = 15\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# input place holders\n",
    "X = tf.placeholder(tf.float32, [None, 784])\n",
    "X_img = tf.reshape(X, [-1, 28, 28, 1])   # img 28x28x1 (black/white)\n",
    "Y = tf.placeholder(tf.float32, [None, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "is_train = tf.placeholder(tf.bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "conv1 = tf.layers.conv2d(inputs=X_img, filters=32, kernel_size=[3, 3],\n",
    "                        padding=\"SAME\", activation=tf.nn.relu)\n",
    "pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2],\n",
    "                        padding=\"SAME\", strides=2)\n",
    "bn1 = tf.layers.batch_normalization(pool1, training=is_train)\n",
    "#bn1 = tf.contrib.layers.batch_norm(pool1, decay=0.9, is_training=is_train)\n",
    "#drop1 = tf.layers.dropout(inputs=pool1, rate=0.3, training=is_train)\n",
    "\n",
    "conv2 = tf.layers.conv2d(inputs=bn1, filters=64, kernel_size=[3, 3],\n",
    "                        padding=\"SAME\", activation=tf.nn.relu)\n",
    "pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2],\n",
    "                        padding=\"SAME\", strides=2)\n",
    "bn2 = tf.layers.batch_normalization(pool2, training=is_train)\n",
    "#bn2 = tf.contrib.layers.batch_norm(pool2, decay=0.9, is_training=is_train)\n",
    "#drop2 = tf.layers.dropout(inputs=pool2, rate=0.3, training=is_train)\n",
    "\n",
    "conv3 = tf.layers.conv2d(inputs=bn2, filters=128, kernel_size=[3, 3],\n",
    "                        padding=\"SAME\", activation=tf.nn.relu)\n",
    "pool3 = tf.layers.max_pooling2d(inputs=conv3, pool_size=[2, 2],\n",
    "                        padding=\"SAME\", strides=2)\n",
    "bn3 = tf.layers.batch_normalization(pool3, training=is_train)\n",
    "#bn3 = tf.contrib.layers.batch_norm(pool3, decay=0.9, is_training=is_train)\n",
    "#drop3 = tf.layers.dropout(inputs=pool3, rate=0.3, training=is_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "flat3 = tf.contrib.layers.flatten(bn3)\n",
    "dense4 = tf.layers.dense(inputs=flat3, units=625, activation=tf.nn.relu)\n",
    "bn4 = tf.layers.batch_normalization(dense4, training=is_train)\n",
    "#bn4 = tf.contrib.layers.batch_norm(dense4, decay=0.9, is_training=is_train)\n",
    "#drop4 = tf.layers.dropout(inputs=dense4, rate=0.5, training=is_train)\n",
    "\n",
    "logits = tf.layers.dense(inputs=bn4, units=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-8-7a12b0f68688>:2: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See tf.nn.softmax_cross_entropy_with_logits_v2.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "    logits=logits, labels=Y))\n",
    "update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "with tf.control_dependencies(update_ops):\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "#optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# initialize\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning started. It takes sometime.\n",
      "Epoch: 0001 cost = 0.090544845\n",
      "Epoch: 0002 cost = 0.033441296\n",
      "Epoch: 0003 cost = 0.023654634\n",
      "Epoch: 0004 cost = 0.016837664\n",
      "Epoch: 0005 cost = 0.014183738\n",
      "Epoch: 0006 cost = 0.014197613\n",
      "Epoch: 0007 cost = 0.009713348\n",
      "Epoch: 0008 cost = 0.009932641\n",
      "Epoch: 0009 cost = 0.010119768\n",
      "Epoch: 0010 cost = 0.008584140\n",
      "Epoch: 0011 cost = 0.007716434\n",
      "Epoch: 0012 cost = 0.005443310\n",
      "Epoch: 0013 cost = 0.006835984\n",
      "Epoch: 0014 cost = 0.006758104\n",
      "Epoch: 0015 cost = 0.005403250\n",
      "Learning Finished!\n"
     ]
    }
   ],
   "source": [
    "# train my model\n",
    "print('Learning started. It takes sometime.')\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0\n",
    "    total_batch = int(mnist.train.num_examples / batch_size)\n",
    "\n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        feed_dict = {X: batch_xs, Y: batch_ys, is_train: True}\n",
    "        #feed_dict = {X: batch_xs, Y: batch_ys, keep_prob: 0.7}\n",
    "        c, _ = sess.run([cost, optimizer], feed_dict=feed_dict)\n",
    "        avg_cost += c / total_batch\n",
    "\n",
    "    print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.9f}'.format(avg_cost))\n",
    "\n",
    "print('Learning Finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy Evaluates\n",
      "-------------------------------\n",
      "Train Accuracy: 0.99644\n",
      "Test Accuracy: 0.99060\n"
     ]
    }
   ],
   "source": [
    "def evaluate(X_sample, y_sample, batch_size=100):\n",
    "    \"\"\"Run a minibatch accuracy op\"\"\"\n",
    "\n",
    "    N = X_sample.shape[0]\n",
    "    correct_sample = 0\n",
    "\n",
    "    for i in range(0, N, batch_size):\n",
    "        X_batch = X_sample[i: i + batch_size]\n",
    "        y_batch = y_sample[i: i + batch_size]\n",
    "        N_batch = X_batch.shape[0]\n",
    "\n",
    "        feed = {\n",
    "            X: X_batch,\n",
    "            Y: y_batch,\n",
    "            is_train: False\n",
    "        }\n",
    "\n",
    "        correct_sample += sess.run(accuracy, feed_dict=feed) * N_batch\n",
    "\n",
    "    return correct_sample / N\n",
    "\n",
    "print(\"\\nAccuracy Evaluates\")\n",
    "print(\"-------------------------------\")\n",
    "print('Train Accuracy:', '{:.5f}'.format(evaluate(mnist.train.images, mnist.train.labels)))\n",
    "print('Test Accuracy:', '{:.5f}'.format(evaluate(mnist.test.images, mnist.test.labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label:  [7]\n",
      "Prediction:  [7]\n"
     ]
    }
   ],
   "source": [
    "# Get one and predict\n",
    "r = random.randint(0, mnist.test.num_examples - 1)\n",
    "print(\"Label: \", sess.run(tf.argmax(mnist.test.labels[r:r + 1], 1)))\n",
    "print(\"Prediction: \", sess.run(\n",
    "    tf.argmax(logits, 1), feed_dict={X: mnist.test.images[r:r + 1], is_train: False}))\n",
    "    #tf.argmax(logits, 1), feed_dict={X: mnist.test.images[r:r + 1], keep_prob: 1.}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x22e142b3860>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(mnist.test.images[r:r + 1].\n",
    "          reshape(28, 28), cmap='Greys', interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
