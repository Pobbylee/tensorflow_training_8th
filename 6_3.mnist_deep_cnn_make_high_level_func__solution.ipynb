{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "tf.set_random_seed(777)  # reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def weight_variable(shape):\n",
    "    #initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    initial = tf.random_normal(shape, stddev=0.1)\n",
    "    #return tf.get_variable(name, shape=shape, initializer=tf.contrib.layers.xavier_initializer())\n",
    "    return tf.Variable(initial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bias_variable(shape):\n",
    "    initial = tf.random_normal(shape=shape, stddev=0.1)\n",
    "    return tf.Variable(initial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv2d(inputs, filters, kernel_size=[3,3], strides=[1,1], activation='Relu', padding='SAME'):\n",
    "    w_shape = kernel_size + [int(inputs.get_shape()[3])] + [filters]    \n",
    "    w = weight_variable(w_shape)    \n",
    "    strides = [1] + strides + [1]\n",
    "    layer = tf.nn.conv2d(inputs, w, strides=strides, padding=padding)\n",
    "    if activation == 'Relu':        \n",
    "        layer = tf.nn.relu(layer)\n",
    "    elif activation == 'Sigmoid':\n",
    "        layer = tf.nn.sigmoid(layer)\n",
    "    else:\n",
    "        layer = layer    \n",
    "    return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def maxpool2d(inputs, pool_size=[2,2], strides=[2,2], padding='SAME'):\n",
    "    ksize = [1] + pool_size + [1]\n",
    "    strides = [1] + strides + [1]\n",
    "    return tf.nn.max_pool(inputs, ksize=ksize, strides=strides, padding=padding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def flatten(inputs):\n",
    "    in_shape = inputs.get_shape()\n",
    "    return tf.reshape(inputs, [-1, int(in_shape[1]) * int(in_shape[2]) * int(in_shape[3])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dense(inputs, units, activation='None'):\n",
    "    w_shape = [int(inputs.get_shape()[1]), units]    \n",
    "    w = weight_variable(w_shape)\n",
    "    b = bias_variable([units])\n",
    "    layer = tf.nn.bias_add(tf.matmul(inputs, w), b)\n",
    "    if activation == 'Relu':        \n",
    "        layer = tf.nn.relu(layer)\n",
    "    elif activation == 'Sigmoid':\n",
    "        layer = tf.nn.sigmoid(layer)\n",
    "    else:\n",
    "        layer = layer    \n",
    "    return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dropout(inputs, rate=0.5, training=False):\n",
    "    keep_prob = 1. - rate\n",
    "    layer = tf.cond(training, lambda: tf.nn.dropout(inputs, keep_prob=keep_prob), lambda: inputs)\n",
    "    return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data/train-images-idx3-ubyte.gz\n",
      "Extracting ../data/train-labels-idx1-ubyte.gz\n",
      "Extracting ../data/t10k-images-idx3-ubyte.gz\n",
      "Extracting ../data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"../data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# hyper parameters\n",
    "learning_rate = 0.001\n",
    "training_epochs = 15\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "is_train = tf.placeholder(tf.bool)\n",
    "keep_prob = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# input place holders\n",
    "X = tf.placeholder(tf.float32, [None, 784])\n",
    "X_img = tf.reshape(X, [-1, 28, 28, 1])   # img 28x28x1 (black/white)\n",
    "Y = tf.placeholder(tf.float32, [None, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "conv1 = conv2d(X_img, 32)\n",
    "pool1 = maxpool2d(conv1)\n",
    "drop1 = dropout(pool1, rate=0.3, training=is_train)\n",
    "#drop1 = tf.nn.dropout(pool1, keep_prob=keep_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "conv2 = conv2d(drop1, 64)\n",
    "pool2 = maxpool2d(conv2)\n",
    "drop2 = dropout(pool2, rate=0.3, training=is_train)\n",
    "#drop2 = tf.nn.dropout(pool2, keep_prob=keep_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "conv3 = conv2d(drop2, 128)\n",
    "pool3 = maxpool2d(conv3)\n",
    "drop3 = dropout(pool3, rate=0.3, training=is_train)\n",
    "#drop3 = tf.nn.dropout(pool3, keep_prob=keep_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "flat3 = flatten(drop3)\n",
    "dense4 = dense(flat3, 625, activation='Relu')\n",
    "drop4 = dropout(dense4, rate=0.5, training=is_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "logits = dense(drop4, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "    logits=logits, labels=Y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# initialize\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning started. It takes sometime.\n",
      "Epoch: 0001 cost = 0.734005893\n",
      "Epoch: 0002 cost = 0.172010866\n",
      "Epoch: 0003 cost = 0.120308275\n",
      "Epoch: 0004 cost = 0.094193271\n",
      "Epoch: 0005 cost = 0.079330593\n",
      "Epoch: 0006 cost = 0.069701576\n",
      "Epoch: 0007 cost = 0.063716632\n",
      "Epoch: 0008 cost = 0.055035657\n",
      "Epoch: 0009 cost = 0.052626130\n",
      "Epoch: 0010 cost = 0.049230541\n",
      "Epoch: 0011 cost = 0.044313142\n",
      "Epoch: 0012 cost = 0.042012643\n",
      "Epoch: 0013 cost = 0.042804789\n",
      "Epoch: 0014 cost = 0.037570624\n",
      "Epoch: 0015 cost = 0.036099037\n",
      "Learning Finished!\n"
     ]
    }
   ],
   "source": [
    "# train my model\n",
    "print('Learning started. It takes sometime.')\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0\n",
    "    total_batch = int(mnist.train.num_examples / batch_size)\n",
    "\n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        feed_dict = {X: batch_xs, Y: batch_ys, is_train: True}\n",
    "        #feed_dict = {X: batch_xs, Y: batch_ys, keep_prob: 0.7}\n",
    "        c, _ = sess.run([cost, optimizer], feed_dict=feed_dict)\n",
    "        avg_cost += c / total_batch\n",
    "\n",
    "    print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.9f}'.format(avg_cost))\n",
    "\n",
    "print('Learning Finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9946\n",
      "Label:  [4]\n",
      "Prediction:  [4]\n"
     ]
    }
   ],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "print('Accuracy:', sess.run(accuracy, feed_dict={\n",
    "      X: mnist.test.images, Y: mnist.test.labels, is_train: False}))\n",
    "      #X: mnist.test.images, Y: mnist.test.labels, keep_prob: 1.}))\n",
    "\n",
    "# Get one and predict\n",
    "r = random.randint(0, mnist.test.num_examples - 1)\n",
    "print(\"Label: \", sess.run(tf.argmax(mnist.test.labels[r:r + 1], 1)))\n",
    "print(\"Prediction: \", sess.run(\n",
    "    tf.argmax(logits, 1), feed_dict={X: mnist.test.images[r:r + 1], is_train: False}))\n",
    "    #tf.argmax(logits, 1), feed_dict={X: mnist.test.images[r:r + 1], keep_prob: 1.}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nhH4PQv0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x15d30a90748>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(mnist.test.images[r:r + 1].\n",
    "          reshape(28, 28), cmap='Greys', interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
