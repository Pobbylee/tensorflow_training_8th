{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_width = 64\n",
    "img_height = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tfrecord_train = 'train.tfrecord'\n",
    "tfrecord_test = 'test.tfrecord'\n",
    "tfrecord_dir = 'tfrecords'\n",
    "cur_dir = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# hyper parameters\n",
    "learning_rate = 0.001\n",
    "training_epochs = 70\n",
    "batch_size = 64\n",
    "n_class = 20\n",
    "n_train = 11409\n",
    "n_test = 2853\n",
    "seed = 777\n",
    "tf.set_random_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_tfr_path = os.path.join(cur_dir, tfrecord_dir, tfrecord_train)\n",
    "test_tfr_path = os.path.join(cur_dir, tfrecord_dir, tfrecord_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def _parse_function(tfrecord_serialized):\n",
    "    features={'image': tf.FixedLenFeature([], tf.string),\n",
    "             'label': tf.FixedLenFeature([], tf.int64)}\n",
    "    parsed_features = tf.parse_single_example(tfrecord_serialized, features)\n",
    "    \n",
    "    image = tf.decode_raw(parsed_features['image'], tf.uint8)\n",
    "    label = tf.cast(parsed_features['label'], tf.int32)\n",
    "    label_onehot = tf.one_hot(label, depth=n_class)\n",
    "    \n",
    "    print(image.shape)\n",
    "    print(label_onehot.shape)\n",
    "        \n",
    "    #image = tf.reshape(image, [-1, img_height, img_width, 3])\n",
    "    \n",
    "    return image, label_onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?,)\n",
      "(20,)\n"
     ]
    }
   ],
   "source": [
    "train_dataset = tf.data.TFRecordDataset(train_tfr_path)\n",
    "train_dataset = train_dataset.map(_parse_function, num_parallel_calls=8)\n",
    "train_dataset = train_dataset.shuffle(buffer_size=10000).prefetch(buffer_size=batch_size).batch(batch_size).repeat()\n",
    "#print(train_dataset.output_types, train_dataset.output_shapes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?,)\n",
      "(20,)\n"
     ]
    }
   ],
   "source": [
    "test_dataset = tf.data.TFRecordDataset(test_tfr_path)\n",
    "test_dataset = test_dataset.map(_parse_function, num_parallel_calls=8)\n",
    "test_dataset = test_dataset.shuffle(buffer_size=10000).prefetch(buffer_size=batch_size).batch(batch_size).repeat()\n",
    "#print(test_dataset.output_types, test_dataset.output_shapes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "iterator = tf.data.Iterator.from_structure(train_dataset.output_types, train_dataset.output_shapes)\n",
    "image, label = iterator.get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_init = iterator.make_initializer(train_dataset)\n",
    "test_init = iterator.make_initializer(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "image = tf.reshape(image, [-1, img_height, img_width, 3])\n",
    "image = tf.cast(image, tf.float32) / 127.5 - 1\n",
    "is_train = tf.placeholder(tf.bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "conv1 = tf.layers.conv2d(inputs=image, filters=32, kernel_size=[3, 3],\n",
    "                        padding=\"SAME\", activation=tf.nn.relu)\n",
    "pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2],\n",
    "                        padding=\"SAME\", strides=2)\n",
    "bn1 = tf.layers.batch_normalization(pool1, training=is_train)\n",
    "#bn1 = tf.contrib.layers.batch_norm(pool1, decay=0.9, is_training=is_train)\n",
    "#drop1 = tf.layers.dropout(inputs=pool1, rate=0.3, training=is_train)\n",
    "\n",
    "conv2 = tf.layers.conv2d(inputs=bn1, filters=64, kernel_size=[3, 3],\n",
    "                        padding=\"SAME\", activation=tf.nn.relu)\n",
    "pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2],\n",
    "                        padding=\"SAME\", strides=2)\n",
    "bn2 = tf.layers.batch_normalization(pool2, training=is_train)\n",
    "#bn2 = tf.contrib.layers.batch_norm(pool2, decay=0.9, is_training=is_train)\n",
    "#drop2 = tf.layers.dropout(inputs=pool2, rate=0.3, training=is_train)\n",
    "\n",
    "conv3 = tf.layers.conv2d(inputs=bn2, filters=128, kernel_size=[3, 3],\n",
    "                        padding=\"SAME\", activation=tf.nn.relu)\n",
    "pool3 = tf.layers.max_pooling2d(inputs=conv3, pool_size=[2, 2],\n",
    "                        padding=\"SAME\", strides=2)\n",
    "bn3 = tf.layers.batch_normalization(pool3, training=is_train)\n",
    "#bn3 = tf.contrib.layers.batch_norm(pool3, decay=0.9, is_training=is_train)\n",
    "#drop3 = tf.layers.dropout(inputs=pool3, rate=0.3, training=is_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "flat3 = tf.contrib.layers.flatten(bn3)\n",
    "dense4 = tf.layers.dense(inputs=flat3, units=625, activation=tf.nn.relu)\n",
    "bn4 = tf.layers.batch_normalization(dense4, training=is_train)\n",
    "#bn4 = tf.contrib.layers.batch_norm(dense4, decay=0.9, is_training=is_train)\n",
    "#drop4 = tf.layers.dropout(inputs=dense4, rate=0.5, training=is_train)\n",
    "\n",
    "logits = tf.layers.dense(inputs=bn4, units=n_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-14-323a2566f7dc>:2: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See tf.nn.softmax_cross_entropy_with_logits_v2.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "    logits=logits, labels=label))\n",
    "update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "with tf.control_dependencies(update_ops):\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "#optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(label, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# initialize\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning started. It takes sometime.\n",
      "Epoch: 0001 cost = 2.119322794 train accuracy =  0.39484 test accuracy =  0.08949\n",
      "Epoch: 0002 cost = 0.814919351 train accuracy =  0.76088 test accuracy =  0.19354\n",
      "Epoch: 0003 cost = 0.217023518 train accuracy =  0.94724 test accuracy =  0.36151\n",
      "Epoch: 0004 cost = 0.078525910 train accuracy =  0.98420 test accuracy =  0.41939\n",
      "Epoch: 0005 cost = 0.031052787 train accuracy =  0.99596 test accuracy =  0.44318\n",
      "Epoch: 0006 cost = 0.008685850 train accuracy =  0.99947 test accuracy =  0.44780\n",
      "Epoch: 0007 cost = 0.003444484 train accuracy =  0.99965 test accuracy =  0.45597\n",
      "Epoch: 0008 cost = 0.002513108 train accuracy =  0.99982 test accuracy =  0.45135\n",
      "Epoch: 0009 cost = 0.000730380 train accuracy =  1.00000 test accuracy =  0.45277\n",
      "Epoch: 0010 cost = 0.000546132 train accuracy =  1.00000 test accuracy =  0.45099\n",
      "Epoch: 0011 cost = 0.000447383 train accuracy =  1.00000 test accuracy =  0.45064\n",
      "Epoch: 0012 cost = 0.000376379 train accuracy =  1.00000 test accuracy =  0.45312\n",
      "Epoch: 0013 cost = 0.000321873 train accuracy =  1.00000 test accuracy =  0.45384\n",
      "Epoch: 0014 cost = 0.000278507 train accuracy =  1.00000 test accuracy =  0.45703\n",
      "Epoch: 0015 cost = 0.000243096 train accuracy =  1.00000 test accuracy =  0.45668\n",
      "Epoch: 0016 cost = 0.000213603 train accuracy =  1.00000 test accuracy =  0.45597\n",
      "Epoch: 0017 cost = 0.000188718 train accuracy =  1.00000 test accuracy =  0.45597\n",
      "Epoch: 0018 cost = 0.000167462 train accuracy =  1.00000 test accuracy =  0.45703\n",
      "Epoch: 0019 cost = 0.000149167 train accuracy =  1.00000 test accuracy =  0.45384\n",
      "Epoch: 0020 cost = 0.000133287 train accuracy =  1.00000 test accuracy =  0.45455\n",
      "Epoch: 0021 cost = 0.000119431 train accuracy =  1.00000 test accuracy =  0.45419\n",
      "Epoch: 0022 cost = 0.000107254 train accuracy =  1.00000 test accuracy =  0.45419\n",
      "Epoch: 0023 cost = 0.000096521 train accuracy =  1.00000 test accuracy =  0.45526\n",
      "Epoch: 0024 cost = 0.000087010 train accuracy =  1.00000 test accuracy =  0.45384\n",
      "Epoch: 0025 cost = 0.000078558 train accuracy =  1.00000 test accuracy =  0.45490\n",
      "Epoch: 0026 cost = 0.000071014 train accuracy =  1.00000 test accuracy =  0.45455\n",
      "Epoch: 0027 cost = 0.000064275 train accuracy =  1.00000 test accuracy =  0.45455\n",
      "Epoch: 0028 cost = 0.000058234 train accuracy =  1.00000 test accuracy =  0.45490\n",
      "Epoch: 0029 cost = 0.000052803 train accuracy =  1.00000 test accuracy =  0.45597\n",
      "Epoch: 0030 cost = 0.000047919 train accuracy =  1.00000 test accuracy =  0.45668\n",
      "Epoch: 0031 cost = 0.000043509 train accuracy =  1.00000 test accuracy =  0.45810\n",
      "Epoch: 0032 cost = 0.000039533 train accuracy =  1.00000 test accuracy =  0.46023\n",
      "Epoch: 0033 cost = 0.000035938 train accuracy =  1.00000 test accuracy =  0.45845\n",
      "Epoch: 0034 cost = 0.000032682 train accuracy =  1.00000 test accuracy =  0.45774\n",
      "Epoch: 0035 cost = 0.000029734 train accuracy =  1.00000 test accuracy =  0.45632\n",
      "Epoch: 0036 cost = 0.000027062 train accuracy =  1.00000 test accuracy =  0.45561\n",
      "Epoch: 0037 cost = 0.000024634 train accuracy =  1.00000 test accuracy =  0.45561\n",
      "Epoch: 0038 cost = 0.000022431 train accuracy =  1.00000 test accuracy =  0.45597\n",
      "Epoch: 0039 cost = 0.000020429 train accuracy =  1.00000 test accuracy =  0.45632\n",
      "Epoch: 0040 cost = 0.000018608 train accuracy =  1.00000 test accuracy =  0.45703\n",
      "Epoch: 0041 cost = 0.000016954 train accuracy =  1.00000 test accuracy =  0.45739\n",
      "Epoch: 0042 cost = 0.000015447 train accuracy =  1.00000 test accuracy =  0.45739\n",
      "Epoch: 0043 cost = 0.000014078 train accuracy =  1.00000 test accuracy =  0.45668\n",
      "Epoch: 0044 cost = 0.000012830 train accuracy =  1.00000 test accuracy =  0.45632\n",
      "Epoch: 0045 cost = 0.000011693 train accuracy =  1.00000 test accuracy =  0.45703\n",
      "Epoch: 0046 cost = 0.000010659 train accuracy =  1.00000 test accuracy =  0.45703\n",
      "Epoch: 0047 cost = 0.000009715 train accuracy =  1.00000 test accuracy =  0.45774\n",
      "Epoch: 0048 cost = 0.000008854 train accuracy =  1.00000 test accuracy =  0.45810\n",
      "Epoch: 0049 cost = 0.000008072 train accuracy =  1.00000 test accuracy =  0.45810\n",
      "Epoch: 0050 cost = 0.000007358 train accuracy =  1.00000 test accuracy =  0.45845\n",
      "Epoch: 0051 cost = 0.000006708 train accuracy =  1.00000 test accuracy =  0.45810\n",
      "Epoch: 0052 cost = 0.000006114 train accuracy =  1.00000 test accuracy =  0.45632\n",
      "Epoch: 0053 cost = 0.000005572 train accuracy =  1.00000 test accuracy =  0.45597\n",
      "Epoch: 0054 cost = 0.000005078 train accuracy =  1.00000 test accuracy =  0.45490\n",
      "Epoch: 0055 cost = 0.000004628 train accuracy =  1.00000 test accuracy =  0.45348\n",
      "Epoch: 0056 cost = 0.000004217 train accuracy =  1.00000 test accuracy =  0.45277\n",
      "Epoch: 0057 cost = 0.000003845 train accuracy =  1.00000 test accuracy =  0.45277\n",
      "Epoch: 0058 cost = 0.000003504 train accuracy =  1.00000 test accuracy =  0.45206\n",
      "Epoch: 0059 cost = 0.000003193 train accuracy =  1.00000 test accuracy =  0.45277\n",
      "Epoch: 0060 cost = 0.000002910 train accuracy =  1.00000 test accuracy =  0.45277\n",
      "Epoch: 0061 cost = 0.000002652 train accuracy =  1.00000 test accuracy =  0.45277\n",
      "Epoch: 0062 cost = 0.000002416 train accuracy =  1.00000 test accuracy =  0.45277\n",
      "Epoch: 0063 cost = 0.000002200 train accuracy =  1.00000 test accuracy =  0.45277\n",
      "Epoch: 0064 cost = 0.000002004 train accuracy =  1.00000 test accuracy =  0.45206\n",
      "Epoch: 0065 cost = 0.000001824 train accuracy =  1.00000 test accuracy =  0.45135\n",
      "Epoch: 0066 cost = 0.000001662 train accuracy =  1.00000 test accuracy =  0.45170\n",
      "Epoch: 0067 cost = 0.000001511 train accuracy =  1.00000 test accuracy =  0.45348\n",
      "Epoch: 0068 cost = 0.000001376 train accuracy =  1.00000 test accuracy =  0.45206\n",
      "Epoch: 0069 cost = 0.000001253 train accuracy =  1.00000 test accuracy =  0.45206\n",
      "Epoch: 0070 cost = 0.000001140 train accuracy =  1.00000 test accuracy =  0.45206\n",
      "Learning Finished!\n"
     ]
    }
   ],
   "source": [
    "# train my model\n",
    "print('Learning started. It takes sometime.')\n",
    "max_test_acc = 0.\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0.\n",
    "    avg_train_acc = 0.\n",
    "    avg_test_acc = 0.\n",
    "    \n",
    "    total_batch = int(n_train / batch_size)\n",
    "    total_batch_test = int(n_test / batch_size)\n",
    "    \n",
    "    sess.run(train_init)\n",
    "\n",
    "    for i in range(total_batch):\n",
    "        #batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        #batch_xs = batch_xs.reshape(-1, time_steps, element_size)\n",
    "        sess.run([image, label])        \n",
    "        feed_dict = {is_train:True}\n",
    "        acc, c, _ = sess.run([accuracy, cost, optimizer], feed_dict=feed_dict)\n",
    "        avg_cost += c / total_batch\n",
    "        avg_train_acc += acc / total_batch\n",
    "        \n",
    "    sess.run(test_init)\n",
    "        \n",
    "    for i in range(total_batch_test):\n",
    "        #batch_xs, batch_ys = mnist.test.next_batch(batch_size)        \n",
    "        #batch_xs = batch_xs.reshape(-1, time_steps, element_size)\n",
    "        sess.run([image, label])\n",
    "        feed_dict = {is_train:False}\n",
    "        acc = sess.run(accuracy, feed_dict=feed_dict)\n",
    "        avg_test_acc += acc / total_batch_test\n",
    "\n",
    "    print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.9f}'.format(avg_cost), \n",
    "          'train accuracy = ', '{:.5f}'.format(avg_train_acc), \n",
    "          'test accuracy = ', '{:.5f}'.format(avg_test_acc))\n",
    "\n",
    "\n",
    "print('Learning Finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
